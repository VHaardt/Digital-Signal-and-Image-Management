{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["zCCxoGxc4Fih","Y1X_UPRtvHVl"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Demo**<br/>\n","**Master's Degree in Data Science (A.Y. 2023/2024)**<br/>\n","**University of Milano - Bicocca**<br/>\n","\n","Vittorio Haardt, Luca Porcelli"],"metadata":{"id":"SLXrLF32Dt6U"}},{"cell_type":"markdown","source":["You must have a link to the project folder on \"My Drive\" for this demo to work."],"metadata":{"id":"JnRHWZm03nGH"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"o3b-tVDkW2cG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708357646924,"user_tz":-60,"elapsed":32943,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}},"outputId":"189ede29-84ca-4eee-c104-c50873401b56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Installing packages and loading libraries"],"metadata":{"id":"zCCxoGxc4Fih"}},{"cell_type":"code","source":["pip install pydub"],"metadata":{"id":"sJpZjDokx1kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708357654156,"user_tz":-60,"elapsed":7241,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}},"outputId":"94d36986-4daf-43ca-901a-311803593e83"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","import joblib\n","from PIL import Image, ImageFilter, ImageChops\n","from tensorflow.keras.models import load_model\n","from scipy.io import wavfile as wav\n","import IPython.display as ipd\n","from scipy.io import wavfile\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","import torch\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","import time\n","import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","from PIL import Image\n","from tqdm import tqdm\n","import tensorflow as tf\n","from torch.utils import data\n","from torchvision import transforms as T\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","import torch\n","import os\n","import random\n","from pydub import AudioSegment\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"3USkHu55XSs2","executionInfo":{"status":"ok","timestamp":1708357662674,"user_tz":-60,"elapsed":8529,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"Y1X_UPRtvHVl"}},{"cell_type":"code","source":["class Demo(object):\n","    def __init__(self, input_path=None, audio_model_path='/content/drive/MyDrive/Digital/Models/Mono-Dimensional/Support Vector Machine_best_model.pkl', image_model_path=\"/content/drive/MyDrive/Digital/Models/Bi-Dimensional/best_model_ResNet50_lr.h5\"):\n","        self.input_path = input_path\n","        self.audio_model_path = audio_model_path\n","        self.image_model_path = image_model_path\n","\n","    @staticmethod\n","    def combo(input):\n","        rms = np.sqrt(np.mean(input**2))  # Root Mean Square (RMS) level\n","        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=input, n_fft=100))  # Spectral centroid\n","        bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=input, n_fft=100))  # Bandwidth\n","        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(input)[0])  # Zero-crossing rate\n","        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=input, n_fft=100))  # Spectral-roll off\n","        spectrum_magnitude = np.mean(np.abs(librosa.core.magphase(librosa.stft(input))[0])) # Spectrum magnitude\n","        energy = np.sum((input*1.0)**2, keepdims=True)[0] # Energy\n","        return np.array([rms, spectral_centroid, bandwidth, zero_crossing_rate, spectral_rolloff, spectrum_magnitude, energy])\n","\n","    @staticmethod\n","    def is_wav_file(file_path):\n","        try:\n","            librosa.load(file_path, sr=None)\n","            return True\n","        except Exception as e:\n","            print(f\"Error while checking the file {file_path}: {e}\")\n","            return False\n","\n","    @staticmethod\n","    def load_single_audio(file_path, feature_extractor=None, length=int(129235.83204633204), normalize=False):\n","        features = []\n","        if file_path.endswith('.wav') and Demo.is_wav_file(file_path):\n","            signal, _ = librosa.load(file_path, sr=48000)\n","            if len(signal) < length:\n","                signal = np.pad(signal, (0, length - len(signal)))\n","            elif len(signal) > length:\n","                signal = signal[:length]\n","            if feature_extractor is not None:\n","                features = feature_extractor(signal)\n","        if normalize:\n","            eps = 0.001\n","            X_train = np.array(features)\n","            X_train_mean = X_train.mean(axis=0)\n","            X_train_std = X_train.std(axis=0)\n","            X_train = (X_train - X_train_mean + eps) / (X_train_std + eps)\n","            X_train = [row for row in X_train]\n","            return X_train\n","        return features\n","\n","    def audio_emotion(self, input_path, audio_model_path=None, normalize=True):\n","        file_path = input_path\n","        if file_path.endswith('.mp3'):\n","              audio = AudioSegment.from_mp3(file_path)\n","              audio.export(\"/content/drive/MyDrive/Digital/Data/Audio.wav\", format=\"wav\")\n","              file_path=\"/content/drive/MyDrive/Digital/Data/Audio.wav\"\n","        X_audio = Demo.load_single_audio(file_path, feature_extractor=self.combo, normalize=normalize)\n","        if audio_model_path is None:\n","            audio_model_path = self.audio_model_path\n","        best_svc_loaded = joblib.load(audio_model_path)\n","        predictions = best_svc_loaded.predict([X_audio])[0]\n","        print('The following classification is based on the first 2 sec.')\n","        sound_data, sound_rate = librosa.load(input_path)\n","        ipd.display(ipd.Audio(sound_data, rate=sound_rate))\n","        return predictions\n","\n","    def preprocess_image_for_model(file_path):\n","        img = Image.open(file_path)\n","        img_gray = img.convert(\"L\")\n","        kernel_x = ImageFilter.Kernel((3, 3), (-1, 0, 1, -2, 0, 2, -1, 0, 1), 1, 0)\n","        kernel_y = ImageFilter.Kernel((3, 3), (-1, -2, -1, 0, 0, 0, 1, 2, 1), 1, 0)\n","\n","        edges_x = img_gray.filter(kernel_x)\n","        edges_y = img_gray.filter(kernel_y)\n","\n","        final_image = ImageChops.add(edges_x, edges_y)\n","        final_image = final_image.resize((224, 224))\n","\n","        image_array = np.array(final_image)\n","        image_array = np.expand_dims([image_array], axis=-1)\n","\n","        return image_array\n","\n","    def image_emotion(self, input_path, image_model_path=None):\n","        file_path = input_path\n","        img = Image.open(file_path)\n","\n","        # Image preprocessing\n","        image_array = Demo.preprocess_image_for_model(file_path)\n","\n","        # Print image\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.show()\n","\n","        if image_model_path is None:\n","            image_model_path = self.image_model_path\n","        model = load_model(image_model_path, compile=False)\n","        class_labels = [\"Angry\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n","        predicted_class_label = class_labels[np.argmax(model.predict(image_array))]\n","        return predicted_class_label"],"metadata":{"id":"rqLbDXZHobdR","executionInfo":{"status":"ok","timestamp":1708357662675,"user_tz":-60,"elapsed":10,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Logger(object):\n","    \"\"\"Tensorboard logger.\"\"\"\n","\n","    def __init__(self, log_dir):\n","        \"\"\"Initialize summary writer.\"\"\"\n","        self.writer = tf.summary.create_file_writer(log_dir)\n","\n","    def scalar_summary(self, tag, value, step):\n","        \"\"\"Add scalar summary.\"\"\"\n","        with self.writer.as_default():\n","            tf.summary.scalar(tag, value, step=step)\n","            self.writer.flush()\n","\n","def get_loader(image_dir, attr_path, selected_attrs, crop_size=178, image_size=224,\n","              batch_size=16, mode='train', num_workers=1):\n","    \"\"\"Build and return a data loader.\"\"\"\n","    transform = []\n","    if mode == 'train':\n","        transform.append(T.RandomHorizontalFlip())\n","    transform.append(T.CenterCrop(crop_size))\n","    transform.append(T.Resize(image_size))\n","    transform.append(T.ToTensor())\n","    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n","    transform = T.Compose(transform)\n","\n","    dataset = ImageFolder(image_dir, transform)\n","\n","    data_loader = data.DataLoader(dataset=dataset,\n","                                  batch_size=batch_size,\n","                                  shuffle=(mode=='train'),\n","                                  num_workers=num_workers)\n","    return data_loader\n","\n","def make_square(image_path, output_size=(256, 256)):\n","  img = Image.open(image_path)\n","  img = img.resize(output_size, Image.ANTIALIAS)\n","  new_img = Image.new(\"RGB\", output_size, (255, 255, 255))\n","  position = ((output_size[0] - img.size[0]) // 2, (output_size[1] - img.size[1]) // 2)\n","  new_img.paste(img, position)\n","  return new_img\n","\n","def process_images_in_directory(input_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for root, dirs, files in os.walk(input_dir):\n","        for file in files:\n","            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n","                input_path = os.path.join(root, file)\n","                output_subdir = os.path.join(output_dir, os.path.relpath(root, input_dir))\n","                output_path = os.path.join(output_subdir, file)\n","                if not os.path.exists(output_subdir):\n","                    os.makedirs(output_subdir)\n","                square_img = make_square(input_path)\n","                square_img.save(output_path)\n","\n","class ResidualBlock(nn.Module):\n","    \"\"\"Residual Block with instance normalization.\"\"\"\n","    def __init__(self, dim_in, dim_out):\n","        super(ResidualBlock, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True))\n","\n","    def forward(self, x):\n","        return x + self.main(x)\n","\n","\n","class Generator(nn.Module):\n","    \"\"\"Generator network.\"\"\"\n","    def __init__(self, conv_dim=64, c_dim=5, repeat_num=6):\n","        super(Generator, self).__init__()\n","\n","        layers = []\n","        layers.append(nn.Conv2d(3+c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False))\n","        layers.append(nn.InstanceNorm2d(conv_dim, affine=True, track_running_stats=True))\n","        layers.append(nn.ReLU(inplace=True))\n","\n","        # Down-sampling layers.\n","        curr_dim = conv_dim\n","        for i in range(2):\n","            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False))\n","            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True, track_running_stats=True))\n","            layers.append(nn.ReLU(inplace=True))\n","            curr_dim = curr_dim * 2\n","\n","        # Bottleneck layers.\n","        for i in range(repeat_num):\n","            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n","\n","        # Up-sampling layers.\n","        for i in range(2):\n","            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False))\n","            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True))\n","            layers.append(nn.ReLU(inplace=True))\n","            curr_dim = curr_dim // 2\n","\n","        layers.append(nn.Conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=False))\n","        layers.append(nn.Tanh())\n","        self.main = nn.Sequential(*layers)\n","\n","    def forward(self, x, c):\n","        c = c.view(c.size(0), c.size(1), 1, 1)\n","        c = c.repeat(1, 1, x.size(2), x.size(3))\n","        x = torch.cat([x, c], dim=1)\n","        return self.main(x)\n","\n","\n","class Discriminator(nn.Module):\n","    \"\"\"Discriminator network with PatchGAN.\"\"\"\n","    def __init__(self, image_size=128, conv_dim=64, c_dim=5, repeat_num=6):\n","        super(Discriminator, self).__init__()\n","        layers = []\n","        layers.append(nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1))\n","        layers.append(nn.LeakyReLU(0.01))\n","\n","        curr_dim = conv_dim\n","        for i in range(1, repeat_num):\n","            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1))\n","            layers.append(nn.LeakyReLU(0.01))\n","            curr_dim = curr_dim * 2\n","\n","        kernel_size = int(image_size / np.power(2, repeat_num))\n","        self.main = nn.Sequential(*layers)\n","        self.conv1 = nn.Conv2d(curr_dim, 1, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=kernel_size, bias=False)\n","\n","    def forward(self, x):\n","        h = self.main(x)\n","        out_src = self.conv1(h)\n","        out_cls = self.conv2(h)\n","        return out_src, out_cls.view(out_cls.size(0), out_cls.size(1))\n","\n","class Solver(object):\n","\n","  def __init__(self, rafd_loader = None, resume_iters = None, g_lr = 0.0001, d_lr = 0.0001):\n","      \"\"\"Initialize configurations.\"\"\"\n","\n","      # Data loader.\n","      #self.celeba_loader = celeba_loader\n","      self.rafd_loader = rafd_loader\n","\n","      # Model configurations.\n","      self.c_dim = 5\n","      self.image_size = 224\n","      self.g_conv_dim = 64\n","      self.d_conv_dim = 64\n","      self.g_repeat_num = 6\n","      self.d_repeat_num = 6\n","      self.lambda_cls = 1\n","      self.lambda_rec = 10\n","      self.lambda_gp = 10\n","\n","      # Training configurations.\n","      self.batch_size = 16\n","      self.num_iters = 200000\n","      self.num_iters_decay = 100000\n","      self.g_lr = g_lr\n","      self.d_lr = d_lr\n","      self.n_critic = 5\n","      self.beta1 = 0.5\n","      self.beta2 = 0.999\n","      self.resume_iters = resume_iters\n","      self.selected_attrs = ['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']\n","\n","      # Miscellaneous.\n","      self.use_tensorboard = 'True'\n","      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","      # Directories.\n","      self.log_dir = '/content/drive/MyDrive/Digital/stargan/logs'\n","      self.model_save_dir = '/content/drive/MyDrive/Digital/stargan/models'\n","      self.result_dir = '/content/'\n","\n","      # Build the model and tensorboard.\n","      self.build_model()\n","      if self.use_tensorboard:\n","          self.build_tensorboard()\n","\n","  def build_model(self):\n","      \"\"\"Create a generator and a discriminator.\"\"\"\n","      self.G = Generator(self.g_conv_dim, self.c_dim, self.g_repeat_num)\n","      self.D = Discriminator(self.image_size, self.d_conv_dim, self.c_dim, self.d_repeat_num)\n","\n","      self.g_optimizer = torch.optim.Adam(self.G.parameters(), self.g_lr, [self.beta1, self.beta2])\n","      self.d_optimizer = torch.optim.Adam(self.D.parameters(), self.d_lr, [self.beta1, self.beta2])\n","\n","      self.G.to(self.device)\n","      self.D.to(self.device)\n","\n","  def restore_model(self, resume_iters):\n","      \"\"\"Restore the trained generator and discriminator.\"\"\"\n","      #print('Loading the trained models from step {}...'.format(resume_iters))\n","      G_path = os.path.join(self.model_save_dir, '{}-G.ckpt'.format(resume_iters))\n","      D_path = os.path.join(self.model_save_dir, '{}-D.ckpt'.format(resume_iters))\n","      self.G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n","      self.D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))\n","\n","  def build_tensorboard(self):\n","      \"\"\"Build a tensorboard logger.\"\"\"\n","      self.logger = Logger(self.log_dir)\n","\n","  def reset_grad(self):\n","      \"\"\"Reset the gradient buffers.\"\"\"\n","      self.g_optimizer.zero_grad()\n","      self.d_optimizer.zero_grad()\n","\n","  def denorm(self, x):\n","      \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n","      out = (x + 1) / 2\n","      return out.clamp_(0, 1)\n","\n","  def label2onehot(self, labels, dim):\n","      \"\"\"Convert label indices to one-hot vectors.\"\"\"\n","      batch_size = labels.size(0)\n","      out = torch.zeros(batch_size, dim)\n","      out[np.arange(batch_size), labels.long()] = 1\n","      return out\n","\n","  def create_labels(self, c_org, c_dim=5, selected_attrs=None):\n","      \"\"\"Generate target domain labels for debugging and testing.\"\"\"\n","      # Get hair color indices\n","\n","      c_trg_list = []\n","      for i in range(c_dim):\n","          c_trg = self.label2onehot(torch.ones(c_org.size(0))*i, c_dim)\n","\n","          c_trg_list.append(c_trg.to(self.device))\n","      return c_trg_list\n","\n","\n","\n","def starGan(input_directory = None, output_directory = None, Name = None):\n","  if input_directory is None or output_directory is None or Name is None:\n","    raise ValueError(\"Both input_directory and output_directory, and Name must be provided.\")\n","\n","  process_images_in_directory(input_directory, output_directory)\n","\n","  solver = Solver(resume_iters = 200000)\n","  prova_loader = get_loader(output_directory, None, None, 224, 224, 1, 'test', 1)\n","\n","  solver.restore_model(200000)\n","  data_loader = prova_loader\n","\n","  with torch.no_grad():\n","    for i, (x_real, c_org) in enumerate(data_loader):\n","      # Prepare input images and target domain labels.\n","      x_real = x_real.to(solver.device)\n","      c_trg_list = solver.create_labels(c_org, solver.c_dim, solver.selected_attrs)\n","\n","      # Translate images.\n","      x_fake_list = [x_real]\n","      for c_trg in c_trg_list:\n","        x_fake_list.append(solver.G(x_real, c_trg))\n","\n","      # Save the translated images.\n","      x_concat = torch.cat(x_fake_list, dim=3)\n","      result_path = os.path.join(solver.result_dir, '{}-{}.jpg'.format(Name, i+1))\n","      save_image(solver.denorm(x_concat.data.cpu()), result_path, nrow=1, padding=0)\n","      #print('Saved real and fake images into {}...'.format(result_path))\n","      img = Image.open(result_path)\n","      plt.figure(figsize=(15, 10))\n","      plt.imshow(img)\n","      plt.axis('off')\n","      plt.show()"],"metadata":{"id":"79x3gTLxkGEA","executionInfo":{"status":"ok","timestamp":1708357685452,"user_tz":-60,"elapsed":436,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Demo showcase"],"metadata":{"id":"zkJ_WEMSvOZ6"}},{"cell_type":"code","source":["demo = Demo()"],"metadata":{"id":"rroqn63RomSD","executionInfo":{"status":"ok","timestamp":1708357692629,"user_tz":-60,"elapsed":424,"user":{"displayName":"Luca Porcelli","userId":"03969269359068115940"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["demo.audio_emotion(input_path = \"/content/drive/MyDrive/Digital/Data/Audio_Demo.mp3\")"],"metadata":{"id":"RKShWFBtnSlU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.image_emotion(input_path=\"/content/drive/MyDrive/Digital/Data/Imm_Demo.jpg\")#Imm_Demo3.png"],"metadata":{"id":"XhKGuIOEGCqv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["starGan(input_directory = '/content/drive/MyDrive/Digital/Data/Luca',\n","        output_directory = '/content/Luca',\n","        Name = 'imm')"],"metadata":{"id":"wMAKX1ukpGJk"},"execution_count":null,"outputs":[]}]}